{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Importing Packages"
      ],
      "metadata": {
        "id": "7SG84kEFW5ws"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "SERNDLoCVwAe"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Lambda, Dropout, BatchNormalization\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau, TensorBoard\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.regularizers import l2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the folder path and .csv file path"
      ],
      "metadata": {
        "id": "lCoshg7DXZqq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Reference : https://www.kaggle.com/code/suraj520/siamese-network-100-acc-know-train-infer\n",
        "train_dataset = pd.read_csv(\"PATH_TO_CSV_FILE\")\n",
        "train_dir = \"PATH_TO_TRAINING DATA\""
      ],
      "metadata": {
        "id": "Fld8cAqCXP7i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining data loader class for image convertion and creating batches."
      ],
      "metadata": {
        "id": "3UfPNOqlZMcA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Reference : https://www.kaggle.com/code/suraj520/siamese-network-100-acc-know-train-infer\n",
        "\n",
        "normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
        "class DataLoader:\n",
        "  #constructor\n",
        "  def __init__(self, dataset, batch_size,dir):\n",
        "    self.dataset = dataset\n",
        "    self.batch_size = batch_size\n",
        "    self.dir = dir\n",
        "  #shuffler\n",
        "  def shuffle(self):\n",
        "    return self.dataset.sample(frac=1)\n",
        "  #generator\n",
        "  def datagen(self):\n",
        "    num_samples = len(self.dataset)\n",
        "    while True:\n",
        "        # shuffling the samples\n",
        "        self.dataset = self.shuffle()\n",
        "        for batch in range(1, num_samples, self.batch_size):\n",
        "            image1_batch_samples = self.dir + \"/\" + self.dataset.iloc[:, 0][batch:batch + self.batch_size]\n",
        "            image2_batch_samples = self.dir + \"/\" + self.dataset.iloc[:, 1][batch:batch + self.batch_size]\n",
        "            label_batch_samples = self.dataset.iloc[:, 2][batch:batch + self.batch_size]\n",
        "            Image1, Image2, Label = [], [], []\n",
        "            for image1, image2, label in zip(image1_batch_samples, image2_batch_samples, label_batch_samples):\n",
        "                # append them to Images directly\n",
        "                image1_data = Image.open(image1)\n",
        "                image2_data = Image.open(image2)\n",
        "                # resizing the images\n",
        "                image1_data = image1_data.resize((224,224))\n",
        "                image2_data = image2_data.resize((224,224))\n",
        "                # converting to grey scale\n",
        "                image1_data = image1_data.convert('L')\n",
        "                image2_data = image2_data.convert('L')\n",
        "                #normalization_layer\n",
        "                image1_data=normalization_layer(image1_data)\n",
        "                image1_data=normalization_layer(image1_data)\n",
        "                # converting to array\n",
        "                image1_data = img_to_array(image1_data)\n",
        "                image2_data = img_to_array(image2_data)\n",
        "                Image1.append(image1_data)\n",
        "                Image2.append(image2_data)\n",
        "                Label.append(label)\n",
        "            # convert each list to numpy arrays to ensure that they get processed by fit function\n",
        "            Image1 = np.asarray(Image1).astype(np.float32)\n",
        "            Image2 = np.asarray(Image2).astype(np.float32)\n",
        "            Label = np.asarray(Label).astype(np.float32)\n",
        "            yield [Image1, Image2], Label\n"
      ],
      "metadata": {
        "id": "RRNKKdPUXhQb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pre-processing the  images"
      ],
      "metadata": {
        "id": "Dt6L9V6GkLS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Reference : https://www.kaggle.com/code/suraj520/siamese-network-100-acc-know-train-infer\n",
        "train_set, val_set = train_test_split(train_dataset, test_size=0.25)\n",
        "train_gen= DataLoader(train_set,128,train_dir)\n",
        "val_gen = DataLoader(val_set,128,train_dir)\n",
        "train_batch = next(train_gen.datagen())\n",
        "print(\"Train batch images shape:\", train_batch[0][0].shape, train_batch[0][1].shape)\n",
        "print(\"Train batch labels shape:\", train_batch[1].shape)"
      ],
      "metadata": {
        "id": "fKPMXHkAZH1O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define Ecludiean Distance"
      ],
      "metadata": {
        "id": "NaYrQO0rkVGt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# reference : https://keras.io/examples/vision/siamese_contrastive/\n",
        "def euclidean_distance(vects):\n",
        "    x, y = vects\n",
        "    sum_square = tf.math.reduce_sum(tf.math.square(x - y), axis=1, keepdims=True)\n",
        "    return tf.math.sqrt(tf.math.maximum(sum_square, tf.keras.backend.epsilon()))\n"
      ],
      "metadata": {
        "id": "VgLqEvN9bKEF"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define Contrastive Loss"
      ],
      "metadata": {
        "id": "YBdpIyFIkZO4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# reference : https://keras.io/examples/vision/siamese_contrastive/\n",
        "def loss(margin=1):\n",
        "    def contrastive_loss(y_true, y_pred):\n",
        "\n",
        "        square_pred = tf.math.square(y_pred)\n",
        "        margin_square = tf.math.square(tf.math.maximum(margin - (y_pred), 0))\n",
        "        return tf.math.reduce_mean(\n",
        "            (1 - y_true) * square_pred + (y_true) * margin_square\n",
        "        )\n",
        "\n",
        "    return contrastive_loss"
      ],
      "metadata": {
        "id": "tynExGoWbXSL"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining Siamese Network"
      ],
      "metadata": {
        "id": "3RlnPfKEkeqF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Reference : https://www.kaggle.com/code/suraj520/siamese-network-100-acc-know-train-infer\n",
        "def Siamese_Network(input_shape):\n",
        "    input1 = Input(input_shape)\n",
        "    input2 = Input(input_shape)\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(64, (3,3), activation='relu', input_shape=input_shape))\n",
        "    model.add(MaxPooling2D(2,2))  # Updated max-pooling to 2x2 with stride 2\n",
        "    model.add(Conv2D(128, (3,3), activation='relu'))  # convolutional layer with 128 filters and 3x3 size\n",
        "    model.add(MaxPooling2D(2,2))\n",
        "    # Flattening Layer\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation='relu')) # Fully connected layer with 128 neurons  &&&&\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(64, activation='relu'))  # Fully connected layer with 64 neurons  &&&\n",
        "    embedding1 = model(input1)\n",
        "    embedding2 = model(input2)\n",
        "    model.summary()\n",
        "    Ecudiean_distance = layers.Lambda(euclidean_distance)([embedding1, embedding2])\n",
        "    output = Dense(1, activation='sigmoid')(Ecudiean_distance)\n",
        "    network = Model(inputs=[input1, input2], outputs=output)\n",
        "    return network"
      ],
      "metadata": {
        "id": "UEPviTj1bJDP"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining Check points for weights."
      ],
      "metadata": {
        "id": "rO8IIEEskhXE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Reference : https://www.kaggle.com/code/suraj520/siamese-network-100-acc-know-train-infer\n",
        "best_weights_path = \"/content/drive/MyDrive/MASTERS_PROJECT/Signature_Verification_Project/Models/Mdoel_weightsGPDS.h5\"\n",
        "model_checkpoint = ModelCheckpoint(\n",
        "    best_weights_path,\n",
        "    monitor='val_loss',  # Choose the metric to monitor for best weights\n",
        "    mode='min',              # Maximize the chosen metric\n",
        "    save_best_only=True,     # Save only the best weights\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "id": "ZO2yY1socUoc"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Reference : https://www.kaggle.com/code/suraj520/siamese-network-100-acc-know-train-infer\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"./logs\")\n",
        "early_stopper =  EarlyStopping(monitor='val_loss',patience=3)\n",
        "custom_callback = [early_stopper,tensorboard_callback,model_checkpoint]\n",
        "model_1 = Siamese_Network((224,224,1))\n",
        "model_1.load_weights(\"Best_Weight_PATHS\")\n",
        "model_1.summary()\n",
        "optimizer = Adam(learning_rate = 0.001)\n",
        "model_1.compile(loss=loss(margin=1),optimizer=optimizer,metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OyBNNZMhcW_E",
        "outputId": "07fc012f-6e50-42e0-e55a-51c65626af4b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_6 (Conv2D)           (None, 222, 222, 64)      640       \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPoolin  (None, 111, 111, 64)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 109, 109, 128)     73856     \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPoolin  (None, 54, 54, 128)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 373248)            0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 128)               47775872  \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 47858624 (182.57 MB)\n",
            "Trainable params: 47858624 (182.57 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_7 (InputLayer)        [(None, 224, 224, 1)]        0         []                            \n",
            "                                                                                                  \n",
            " input_8 (InputLayer)        [(None, 224, 224, 1)]        0         []                            \n",
            "                                                                                                  \n",
            " sequential_3 (Sequential)   (None, 64)                   4785862   ['input_7[0][0]',             \n",
            "                                                          4          'input_8[0][0]']             \n",
            "                                                                                                  \n",
            " lambda_2 (Lambda)           (None, 1)                    0         ['sequential_3[0][0]',        \n",
            "                                                                     'sequential_3[1][0]']        \n",
            "                                                                                                  \n",
            " dense_8 (Dense)             (None, 1)                    2         ['lambda_2[0][0]']            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 47858626 (182.57 MB)\n",
            "Trainable params: 47858626 (182.57 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training and validation of the model"
      ],
      "metadata": {
        "id": "5Yl-VG_7ko8k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Reference : https://www.kaggle.com/code/suraj520/siamese-network-100-acc-know-train-infer\n",
        "batch_size = 128\n",
        "steps_per_epoch = len(train_set) // batch_size\n",
        "validation_steps = len(val_set) // batch_size\n",
        "\n",
        "print(\"Initializing Training !!\")\n",
        "history = model_1.fit(\n",
        "    train_gen.datagen(),\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    epochs=20 ,\n",
        "    validation_data=val_gen.datagen(),\n",
        "    validation_steps=validation_steps,\n",
        "    callbacks=custom_callback\n",
        ")"
      ],
      "metadata": {
        "id": "ayO9KalTda3R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plotting the Training and Validation curves for Accuracy and loss."
      ],
      "metadata": {
        "id": "tGJ2qDf7ktLk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history_keys = history.history.keys()\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "# Plot the accuracy curves\n",
        "if 'accuracy' in history_keys and 'val_accuracy' in history_keys:\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['accuracy'])\n",
        "    plt.plot(history.history['val_accuracy'])\n",
        "    plt.title('Model Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend(['Train', 'Validation'], loc='lower right')\n",
        "\n",
        "# Plot the loss curves\n",
        "if 'loss' in history_keys and 'val_loss' in history_keys:\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('Model Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend(['Train', 'Validation'], loc='upper right')\n",
        "\n",
        "# Adjust the layout and display the plot\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9V0or9dQddxI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "TESTING THE MODEL...\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "mpf6hq8mk1w7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Reference : https://www.kaggle.com/code/suraj520/siamese-network-100-acc-know-train-infer\n",
        "# Paths to the test images and directories\n",
        "test_image_dir = \"PATH_TO_TEST_DATA\"\n",
        "test_csv_path =  pd.read_csv(\"PATH_TO_CSV_FILE_FOR_TEST\")\n",
        "\n",
        "# Prepare test data (assuming you have DataLoader class defined)\n",
        "pred_gen = DataLoader(test_csv_path, batch_size=len(test_csv_path), dir=test_image_dir)\n",
        "images, true_labels = next(pred_gen.datagen())\n",
        "print(\"Train batch images shape:\", images[0].shape, images[1].shape)\n",
        "print(\"Train batch labels shape:\", len(true_labels))"
      ],
      "metadata": {
        "id": "o8P92YpxdhAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Reference : https://www.kaggle.com/code/suraj520/siamese-network-100-acc-know-train-infer\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score\n",
        "from scipy.optimize import brentq\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import auc\n",
        "from scipy.interpolate import interp1d\n",
        "\n",
        "# Perform predictions\n",
        "predictions = model_1.predict(images)\n",
        "binary_predictions = []\n",
        "for pred in predictions:\n",
        "    if pred >= 0.5:\n",
        "        binary_predictions.append(0)\n",
        "    else:\n",
        "        binary_predictions.append(1)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(true_labels, binary_predictions)\n",
        "f1 = f1_score(true_labels, binary_predictions)\n",
        "confusion_mat = confusion_matrix(true_labels, binary_predictions)\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "# Print confusion matrix with labels and using seaborn\n",
        "class_names = ['Class 0', 'Class 1']\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(confusion_mat, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bP9zu3Ardg7P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "EVALUATION MATRIX"
      ],
      "metadata": {
        "id": "4J5r9o1Lk7dP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "frr = 1 - recall_score(true_labels, binary_predictions)\n",
        "far = 1 - precision_score(true_labels, binary_predictions)\n",
        "aer = (frr + far) / 2\n",
        "fpr, fnr, _ = roc_curve(true_labels, binary_predictions)\n",
        "eer = brentq(lambda x : 1. - x - interp1d(fpr, fnr)(x), 0., 1.)\n",
        "fprt, tpr, _ = roc_curve(true_labels, binary_predictions)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sAVzeD73iaFh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# EER, FRR, AER,FAR\n",
        "print(\"Equal Error Rate (EER):\", round(eer,2))\n",
        "print(\"False Rejection Rate (FRR):\", round(frr,2))\n",
        "print(\"False Acceptance Rate (FAR):\", round(far,2))\n",
        "print(\"Average Error Rate (AER):\", round(aer,2))\n",
        "print(\"Accuracy:\", round(accuracy,2))\n",
        "print(\"F1 Score:\", round(f1,2))\n",
        "\n",
        "best_val_accuracy = round(max(history.history['val_accuracy']),2)\n",
        "best_train_accuracy = round(max(history.history['accuracy']),2)\n",
        "print(\"Best Validation Accuracy:\", best_val_accuracy)\n",
        "print(\"Best Training Accuracy:\", best_train_accuracy)"
      ],
      "metadata": {
        "id": "hou2OMDQiebR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking model performance on the image sets"
      ],
      "metadata": {
        "id": "XNAlODEWk_ds"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Reference : https://www.kaggle.com/code/suraj520/siamese-network-100-acc-know-train-infer\n",
        "# Define the paths to the test images\n",
        "test_image1_path = 'PATH_TO_FIRST_IMAGE'\n",
        "test_image2_path = 'PATH_TO_SECOND_IMAGE'\n",
        "\n",
        "# Load and preprocess the test images\n",
        "test_image1 = Image.open(test_image1_path)\n",
        "disply_image_1= Image.open(test_image1_path)\n",
        "test_image1 = test_image1.resize((224,224))\n",
        "test_image1 = test_image1.convert('L')\n",
        "test_image1 = normalization_layer(test_image1)\n",
        "test_image1 = img_to_array(test_image1)\n",
        "test_image1 = np.expand_dims(test_image1, axis=0)\n",
        "test_image1 = test_image1.astype('float32')\n",
        "\n",
        "\n",
        "test_image2 = Image.open(test_image2_path)\n",
        "display_image_2 = Image.open(test_image2_path)\n",
        "test_image2 = test_image2.resize((224,224))\n",
        "test_image2 = test_image2.convert('L')\n",
        "test_image2 = normalization_layer(test_image2)\n",
        "test_image2 = img_to_array(test_image2)\n",
        "test_image2 = np.expand_dims(test_image2, axis=0)\n",
        "test_image2 = test_image2.astype('float32')\n",
        "\n",
        "# Perform inference on the test images\n",
        "prediction = model_1.predict([test_image1, test_image2])\n",
        "# Print the similarity score\n",
        "# similarity_score = prediction[0][0]\n",
        "# print('Similarity Score:', similarity_score)\n",
        "Result = []\n",
        "if prediction <=0.5:\n",
        "  Result = \"FORGED\"\n",
        "else :\n",
        "  Result = \"REAL\"\n",
        "\n",
        "# Display the test images with the similarity score as legend\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(disply_image_1)\n",
        "plt.title('Test Image 1')\n",
        "plt.axis('off')\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(display_image_2)\n",
        "plt.title('Test Image 2')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.suptitle(f'Result: {Result}', fontsize=12)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rht5g8oAirfD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}